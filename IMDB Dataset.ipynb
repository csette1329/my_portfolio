{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c840825e-0d7a-49e2-b214-0bc752365ea2",
   "metadata": {},
   "source": [
    "# Conclusions of Random Forests model applied to IMDB Movie Dataset to predict Average Rating\n",
    "\n",
    "## Mean Absolute Error\n",
    "\n",
    "We obtained a MAE of 0.26, pretty accurate considering a scale of 0-10 for IMBD rating.\n",
    "\n",
    "## Features Importance\n",
    "\n",
    "1. **Worldwide_Gross**: most important feature to predict movie IMBD rating (makes sense)\n",
    "   \n",
    "2. **Metascore**: second most important feature to predict movie IMDB rating (makes sense) \n",
    "\n",
    "3. **Budget**: least importante feature to predict movie IMBD rating (a bit surprising, perhaps the best rated movies not always had the greatest budgets)\n",
    "\n",
    "## Real Values vs Predicted Values\n",
    "\n",
    "The scatterplot shows that for lowest rating movies, our predictions for IMDB rating were more \"optmistic\". But as we move right on our x-axis (real values), we can see that our model can make better predictions. Finally, for higher ratings, our model becomes more \"pessimistic\", and also the accuracy decreases greatly.\n",
    "\n",
    "## Error Distribution\n",
    "\n",
    "Our graph shows that 80% of our values had an absolute error of 0.4 or less.\n",
    "\n",
    "### Final comments\n",
    "\n",
    "This model is simple but yet had a decent accuracy for predicting movies IMDB ratings based on the features ['Metascore','Budget','Worldwide_Gross']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e5f3c-f26b-44ed-8b8d-5a6ac01a9c5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('IMDB_Movies_Dataset.csv')\n",
    "df = df.set_index(df.columns[0])\n",
    "df.index.name = 'Index' \n",
    "\n",
    "# Remove spaces from columns names\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "# Remover NaNs\n",
    "df = df.dropna()\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7f0d6-9c97-46b5-b3bf-4a7a0c683500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b946aa1-0f11-4c9b-917e-111367028cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b7905-9f0b-43b4-ad16-6a1c91c096bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract numeric values\n",
    "import re\n",
    "\n",
    "# Clean and convert 'budget' column\n",
    "def clean_convert(value):\n",
    "    # Remove all non-numeric values\n",
    "    clean_value = re.sub(r'[^0-9]', '', value)\n",
    "    return clean_value\n",
    "\n",
    "# Apply function to 'budget' column and convert values to numeric type\n",
    "df_train['Budget'] = df_train['Budget'].apply(clean_convert)\n",
    "df_train['Budget'] = pd.to_numeric(df_train['Budget'])\n",
    "\n",
    "# Verify result\n",
    "print(df_train['Budget'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00868fac-28c8-4e9b-b3d9-ba67c07d6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to 'Worldwide_Gross' column and convert values to numeric type \n",
    "df_train['Worldwide_Gross'] = df_train['Worldwide_Gross'].apply(clean_convert)\n",
    "df_train['Worldwide_Gross'] = pd.to_numeric(df_train['Worldwide_Gross'])\n",
    "\n",
    "# Verify result\n",
    "print(df_train['Worldwide_Gross'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb1af4d1-17eb-4ec9-8642-98811b202c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose target and features\n",
    "y = df_train.Average_Rating\n",
    "features = ['Metascore','Budget','Worldwide_Gross']\n",
    "X = df_train[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8c6ccc4-2c88-4917-b120-6069facf11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into training and validation subsets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72742bbc-723a-474e-b19a-efc5e1b83138",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd099f6a-dbe8-4526-b72c-51692e009135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Apply random forests model\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(X_train, y_train)\n",
    "\n",
    "movie_preds = forest_model.predict(X_valid)\n",
    "print(mean_absolute_error(y_valid, movie_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a10afe-8309-4494-a187-51b1823a43c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Measuring Features importance\n",
    "# Defining importances.\n",
    "importances = forest_model.feature_importances_\n",
    "\n",
    "# Creating a dataframe with importances\n",
    "feature_importance_df = pd.DataFrame({'feature': features, 'importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Plotting importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance_df)\n",
    "plt.title('Features Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7886a613-22c9-4f0b-9281-cea7ba95a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of predicted values vs validation values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_valid, movie_preds, alpha=0.3)\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], 'r--')  # Reference line\n",
    "plt.xlabel('Validation values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Real values vs. Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314896e0-09b9-43ff-a389-af83df40e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of predicted values vs validation values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_valid, movie_preds, alpha=0.3)\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], 'r--')  # Reference line\n",
    "plt.xlabel('Validation values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Real values vs. Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a85da38-a82c-4538-9f05-4709196866f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Error distribution\n",
    "y_pred = movie_preds.copy()\n",
    "y_test = y_valid.copy()\n",
    "errors = abs(y_pred - y_test)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(errors, bins=25, edgecolor='k', alpha=0.7)\n",
    "plt.xlabel('Absolute Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Error Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3575b-8424-45dc-a79f-e58f16e4f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error distribution\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = movie_preds.copy()\n",
    "y_test = y_valid.copy()\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred - y_test)\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot the histogram of errors\n",
    "counts, bins, patches = ax1.hist(errors, bins=25, edgecolor='k', alpha=0.7)\n",
    "ax1.set_xlabel('Absolute Error')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Error Distribution')\n",
    "\n",
    "# Set up the secondary y-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Calculate the cumulative percentage of frequency\n",
    "cum_counts = np.cumsum(counts)\n",
    "cum_perc = cum_counts / cum_counts[-1] * 100\n",
    "\n",
    "# Plot the red line for cumulative percentage\n",
    "ax2.plot(bins[:-1], cum_perc, 'r-', linewidth=2, label='Cumulative Percentage')\n",
    "ax2.set_ylabel('Cumulative Percentage (%)')\n",
    "ax2.legend(loc='upper left')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a895e-11b0-4eb5-9ac4-da942c71f791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
